---
layout: post
categories: [scala]
title: TFIDF结果含义
date: 2019-01-28
author: TTyb
desc: "import org.apache.spark.ml.feature.{HashingTF, IDF}库中，TFIDF结果的字段含义"
---

# TFIDF

词频（TF）和逆文档频率（IDF）字段公式为：

词频（TF）= 某个词在文章中的出现次数

或者

词频（TF）=  某个词在文章中的出现次数 / 文章总词数

逆文档频率（IDF）= log(语料库文档总数 / (包含该词的文档数 + 1))

$ TF-IDF = TF x IDF $



# 代码以及结果含义

~~~ruby
import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.sql.SQLContext
import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}

object test {

  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setAppName("TTyb").setMaster("local")
    val sc = new SparkContext(conf)
    val spark = new SQLContext(sc)

    val sentenceData = spark.createDataFrame(Seq(
      (0, "Hi I heard about Spark"),
      (1, "I wish Java could use case classes"),
      (2, "Logistic,regression,models,are,neat")
    )).toDF("id", "sentence")

    //分词
    val tokenizer = new Tokenizer().setInputCol("sentence").setOutputCol("words")
    val wordsData = tokenizer.transform(sentenceData)
    //TF
    val TFModel = new HashingTF().setInputCol("words").setOutputCol("rawFeatures").setNumFeatures(2000)
    val tf = TFModel.transform(wordsData)
    tf.show(false)
    //IDF
    val idf=new IDF().setInputCol("rawFeatures").setOutputCol("features")
    val idfModel=idf.fit(tf)
    val TFIDF=idfModel.transform(tf)

  }

}
~~~

结果如下：

~~~ruby
+---+-----------------------------------+------------------------------------------+---------------------------------------------------------------------+
|id |sentence                           |words                                     |rawFeatures                                                          |
+---+-----------------------------------+------------------------------------------+---------------------------------------------------------------------+
|0  |Hi I heard about Spark             |[hi, i, heard, about, spark]              |(2000,[1105,1329,1357,1777,1960],[1.0,1.0,1.0,1.0,1.0])              |
|1  |I wish Java could use case classes |[i, wish, java, could, use, case, classes]|(2000,[213,342,489,495,1329,1809,1967],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])|
|2  |Logistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |(2000,[234],[1.0])                                                   |
+---+-----------------------------------+------------------------------------------+---------------------------------------------------------------------+
~~~

可以看到每一个单词被哈希成了一个不同的索引值。以”Hi I heard about Spark”为例，输出结果中2000代表哈希表的桶数，“[1105,1329,1357,1777,1960]”分别代表着“hi, i, heard, about, spark”的哈希值，“[1.0,1.0,1.0,1.0,1.0]”为对应单词的出现次数。

